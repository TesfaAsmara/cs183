{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "current_timestamp = int(time.time())\n",
    "\n",
    "dining_hall = \"frank\"\n",
    "\n",
    "url = \"https://5cmenu-cache.jojodmo.com/v1/getMenu/?diningHall=\"+dining_hall+\"&startTime=\"+str(current_timestamp)+\"&language=en\"\n",
    "\n",
    "# Make a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the request was successful (HTTP status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Load the JSON data from the response\n",
    "    json_data = response.json()\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve data. HTTP status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'json' from '/opt/homebrew/Caskroom/miniforge/base/envs/chatmapenv/lib/python3.11/json/__init__.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'breakfast': {'meal': 'Breakfast',\n",
       "  'stations': [{'station': 'Desserts',\n",
       "    'stationOriginal': 'Desserts',\n",
       "    'menu': [{'name': 'Assorted Breakfast Pastries and Desserts - Croissants, Muffins, Danish, Scones'},\n",
       "     {'name': 'Vegan Peach Crisp'},\n",
       "     {'name': 'CONTINUOUS DINING Freshly Baked Cookies (May contain allergens coconut, egg, milk, soy, wheat)'}]},\n",
       "   {'station': 'Grill',\n",
       "    'stationOriginal': 'Grill',\n",
       "    'menu': [{'name': 'Scrambled Whole Eggs'},\n",
       "     {'name': 'Scrambled Egg Whites'},\n",
       "     {'name': 'Crispy Cubed Potatoes'},\n",
       "     {'name': 'Tofu Scramble'},\n",
       "     {'name': 'Buttermilk Pancakes'},\n",
       "     {'name': 'Carne Asada Street Tacos'},\n",
       "     {'name': 'Carnitas'},\n",
       "     {'name': 'Mexican Rice'},\n",
       "     {'name': 'Refried Beans'},\n",
       "     {'name': 'Calabacitas (Mexican Squash)'},\n",
       "     {'name': 'Salsa'}]},\n",
       "   {'station': 'Outdoor Dining',\n",
       "    'stationOriginal': 'Outdoor Dining',\n",
       "    'menu': [{'name': 'OUTDOOR OMELET BAR - Scrambled Eggs and Egg Whites, Assorted Veggies, Cheese and Meats'}]},\n",
       "   {'station': 'Clean Eats',\n",
       "    'stationOriginal': 'Clean Eats',\n",
       "    'menu': [{'name': 'Nicoya Blue Zone Bowl - Gallo Pinto, Plantains, Avocado, Chilero Hot Sauce, Baked Tofu, Blue Corn Tortillas'},\n",
       "     {'name': 'Gallo Pinto'},\n",
       "     {'name': 'Baked Plantains'},\n",
       "     {'name': 'Avocado'},\n",
       "     {'name': 'Chilero Hot Sauce (Blue Zone)'},\n",
       "     {'name': 'Simply Baked Tofu'},\n",
       "     {'name': 'Blue Corn Tortillas'},\n",
       "     {'name': 'CONTINUOUS DINING Build Your Own Bowl with Simply Prepared GF Grains, Greens, Proteins and Condiments'}]},\n",
       "   {'station': 'Mainline',\n",
       "    'stationOriginal': 'Mainline',\n",
       "    'menu': [{'name': 'Carne Asada Street Tacos'},\n",
       "     {'name': 'Carnitas'},\n",
       "     {'name': 'Mexican Rice'},\n",
       "     {'name': 'Refried Beans'},\n",
       "     {'name': 'Calabacitas (Mexican Squash)'},\n",
       "     {'name': 'Salsa'},\n",
       "     {'name': 'Guacamole'},\n",
       "     {'name': 'Pico de Gallo'}]},\n",
       "   {'station': 'Pizza',\n",
       "    'stationOriginal': 'Pizza',\n",
       "    'menu': [{'name': 'Pepperoni Pizza'},\n",
       "     {'name': 'Cheese Pizza'},\n",
       "     {'name': 'Garlic Cheese Bread Pizza Squares'},\n",
       "     {'name': 'Bee Sting Flatbread'}]},\n",
       "   {'station': 'Salad Bar',\n",
       "    'stationOriginal': 'Salad Bar',\n",
       "    'menu': [{'name': 'Nopales Salad'},\n",
       "     {'name': 'BERRY and ACAI BOWL STATION'}]},\n",
       "   {'station': 'Soup',\n",
       "    'stationOriginal': 'Soup',\n",
       "    'menu': [{'name': 'Oatmeal'},\n",
       "     {'name': 'Miso Soup'},\n",
       "     {'name': 'Hummus'},\n",
       "     {'name': 'Antipasto Platter with Artichoke Hearts, Olives, Bell Peppers, Pepperoncinis, Cherry Tomatoes, Mushrooms, Italian Vinaigrette, Salami, Capicola, Provolone'}]}],\n",
       "  'startTime': 1695279600,\n",
       "  'endTime': 1695279600},\n",
       " 'dinner': {'meal': 'Dinner',\n",
       "  'stations': [{'station': 'Desserts',\n",
       "    'stationOriginal': 'Desserts',\n",
       "    'menu': [{'name': 'Snickerdoodle Cookies'},\n",
       "     {'name': 'Vegan Fruit Crisp'}]},\n",
       "   {'station': 'Grill',\n",
       "    'stationOriginal': 'Grill',\n",
       "    'menu': [{'name': 'Shrimp Ceviche Tostadas'},\n",
       "     {'name': 'Cauliflower Ceviche Tostadas'}]},\n",
       "   {'station': 'Clean Eats',\n",
       "    'stationOriginal': 'Clean Eats',\n",
       "    'menu': [{'name': 'Okinawan Blue Zone Bowl - Glazed Greens, Kidney Beans, Purple Sweet Potatoes, Baked Tofu, Bok Choy, Bean Sprouts, Shredded Carrot'},\n",
       "     {'name': 'Blue Zone - Okinawan Glazed Greens'},\n",
       "     {'name': 'Kidney Beans'},\n",
       "     {'name': 'Roasted Purple Potatoes'},\n",
       "     {'name': 'Steamed Baby Bok Choy'},\n",
       "     {'name': 'Simply Baked Tofu'},\n",
       "     {'name': 'Shredded Carrot'}]},\n",
       "   {'station': 'Mainline',\n",
       "    'stationOriginal': 'Mainline',\n",
       "    'menu': [{'name': 'Mongolian Beef Stir Fry'},\n",
       "     {'name': 'Baked Tofu'},\n",
       "     {'name': 'Vegetable Chow Mein Noodles'},\n",
       "     {'name': 'Sesame Kale'},\n",
       "     {'name': 'Vegetable Gyoza (Potstickers)'},\n",
       "     {'name': 'Teriyaki Dipping Sauce'},\n",
       "     {'name': 'Steamed Jasmine Rice'}]},\n",
       "   {'station': 'Pizza',\n",
       "    'stationOriginal': 'Pizza',\n",
       "    'menu': [{'name': 'Pepperoni Pizza'},\n",
       "     {'name': 'Cheese Pizza'},\n",
       "     {'name': 'Garlic Cheese Bread Pizza Squares'},\n",
       "     {'name': 'Bee Sting Flatbread'}]},\n",
       "   {'station': 'Soup',\n",
       "    'stationOriginal': 'Soup',\n",
       "    'menu': [{'name': 'Miso Soup'}]}],\n",
       "  'startTime': 1695279600,\n",
       "  'endTime': 1695279600}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[\"response\"][\"menu\"][0][\"meals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for station in json_data[\"response\"][\"stations\"]:\n",
    "#     print(station[\"menu\"])\n",
    "meal_keys = json_data[\"response\"][\"menu\"][0][\"meals\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stations = len(json_data[\"response\"][\"menu\"][0][\"meals\"][\"brunch\"][\"stations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_menu_length = len(json_data[\"response\"][\"menu\"][0][\"meals\"][\"brunch\"][\"stations\"][station_index][\"menu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjson_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmenu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeals\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrunch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omelet Bar\n",
      "Hash Brown Patty\n",
      "Omelet Bar\n",
      "Hash Brown Patty\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m station_menu_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(json_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmenu\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeals\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrunch\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstations\u001b[39m\u001b[38;5;124m\"\u001b[39m][station_entire_menu_index][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmenu\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m station_menu_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(station_menu_length):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mjson_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmenu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeals\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrunch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstation_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmenu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstation_menu_index\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "station_index = 0\n",
    "station_menu_index = 0 \n",
    "for meal_key in meal_keys:\n",
    "    num_stations = len(json_data[\"response\"][\"menu\"][0][\"meals\"][meal_key][\"stations\"])\n",
    "    for station_index in range(num_stations):\n",
    "        station_entire_menu_length = len(json_data[\"response\"][\"menu\"][0][\"meals\"][meal_key][\"stations\"][station_index][\"menu\"])\n",
    "        for station_entire_menu_index in range(station_entire_menu_length):\n",
    "            station_menu_length = len(json_data[\"response\"][\"menu\"][0][\"meals\"][\"brunch\"][\"stations\"][station_entire_menu_index][\"menu\"])\n",
    "            for station_menu_index in range(station_menu_length):\n",
    "                print(json_data[\"response\"][\"menu\"][0][\"meals\"][\"brunch\"][\"stations\"][station_index][\"menu\"][station_menu_index][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in meal_keys:\n",
    "    print(json_data[\"response\"][\"menu\"][0][\"meals\"][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# run this cell to create (and be able to later use) the trial_generator function\n",
    "\n",
    "np.random.seed(22) # seed our random number generator\n",
    "\n",
    "trials_per_day = 16\n",
    "\n",
    "def trial_generator():\n",
    "  trial_vector = np.random.randint(low=0,high=300,size=(trials_per_day))\n",
    "  return trial_vector\n",
    "  # returns a vector of length 16\n",
    "\n",
    "# 3.0\n",
    "mouse1 = np.zeros((5, 16))\n",
    "mouse2 = np.zeros((5, 16))\n",
    "mouse3 = np.zeros((5, 16))\n",
    "\n",
    "#3.1 \n",
    "for i, row in enumerate(mouse1):\n",
    "    mouse1[i:] = trial_generator()\n",
    "    mouse2[i:] = trial_generator()\n",
    "    mouse3[i:] = trial_generator()\n",
    "\n",
    "# 3.2\n",
    "# Calculate mean reaction times for each day (mean along axis 1, i.e., the rows)\n",
    "mean_reaction_times_mouse1 = np.mean(mouse1, axis=1)\n",
    "mean_reaction_times_mouse2 = np.mean(mouse2, axis=1)\n",
    "mean_reaction_times_mouse3 = np.mean(mouse3, axis=1)\n",
    "\n",
    "# 3.3\n",
    "# Calculate the difference in mean performance between day 1 and day 5 for each mouse\n",
    "difference_mouse1 = mean_reaction_times_mouse1[0] - mean_reaction_times_mouse1[-1]\n",
    "difference_mouse2 = mean_reaction_times_mouse2[0] - mean_reaction_times_mouse2[-1]\n",
    "difference_mouse3 = mean_reaction_times_mouse3[0] - mean_reaction_times_mouse3[-1]\n",
    "\n",
    "# Check for improvement (negative difference) and print the results\n",
    "print(\"Difference in mean performance between day 1 and day 5 for each mouse:\")\n",
    "print(\"Mouse 1:\", difference_mouse1, \"ms\", \"Improvement\" if difference_mouse1 < 0 else \"No Improvement\")\n",
    "print(\"Mouse 2:\", difference_mouse2, \"ms\", \"Improvement\" if difference_mouse2 < 0 else \"No Improvement\")\n",
    "print(\"Mouse 3:\", difference_mouse3, \"ms\", \"Improvement\" if difference_mouse3 < 0 else \"No Improvement\")\n",
    "\n",
    "# 3.4\n",
    "mouse1[3:] = trial_generator()\n",
    "mean_reaction_times_mouse1 = np.mean(mouse1, axis=1)\n",
    "\n",
    "# 4\n",
    "A = np.array([[5, 3], [0, 2]])\n",
    "B = np.array([[1, 5], [4, 3]])\n",
    "\n",
    "# Perform matrix multiplication using numpy.dot()\n",
    "C = np.dot(A, B)\n",
    "\n",
    "# 5\n",
    "X = np.array([[3, 2, 1], [1, 2, 7]])\n",
    "Y = np.array([[0, 1], [2, 4], [5,1]])\n",
    "\n",
    "\n",
    "# An easy way to determine the shape of the resulting matrix \n",
    "# is to take the number of rows from the first one \n",
    "# and the number of columns from the second one\n",
    "\n",
    "my_guess = (len(X), len(Y[0]))\n",
    "\n",
    "# Perform matrix multiplication using numpy.dot()\n",
    "Z = np.dot(X, Y)\n",
    "\n",
    "assert my_guess == Z.shape\n",
    "\n",
    "# 6\n",
    "print(X.transpose())\n",
    "\n",
    "# For matrix multiplication, the number of columns in the first matrix \n",
    "# must be equal to the number of rows in the second matrix\n",
    "\n",
    "# 7.0\n",
    "# https://youtu.be/7GD6v-XI1mA\n",
    "A = np.array([[1,0], [0,-1]])\n",
    "\n",
    "# 7.1\n",
    "\n",
    "# We would expect the determinant (ad - bc)\n",
    "# to be negative because a should be 1,b should be 0,\n",
    "# c should be 0, and d should be -1.\n",
    "\n",
    "# 8.0\n",
    "A = np.array([[1,0], [0,0]])\n",
    "\n",
    "# 8.1\n",
    "\n",
    "# We would expect the determinant (ad - bc)\n",
    "# to be zero because a should be 1 and b,c, and d should be 0.\n",
    "\n",
    "# 9.0\n",
    "# The basis vectors remain the same\n",
    "basis_vector_i = np.array([1,0])\n",
    "basis_vector_j = np.array([0,1])\n",
    "\n",
    "# 9.1\n",
    "# https://www.khanacademy.org/math/linear-algebra/matrix-transformations/linear-transformations/a/visualizing-linear-transformations\n",
    "# It stretches it horizontally by (3,0). It stretches it horizontally and vertically by (1,3) respectively.\n",
    "\n",
    "# 9.2\n",
    "# Positive because (ad - bc) = (3*3 - 1*0) = 9\n",
    "\n",
    "# 10\n",
    "# Part A\n",
    "\n",
    "# Define F\n",
    "F = np.array([[1,3,4], [2, 1, 4], [1,5,6]])\n",
    "\n",
    "# Define G\n",
    "G = np.array([[0,1,1], [0, 6, 10], [3,6,1]])\n",
    "\n",
    "# Part B\n",
    "\n",
    "# Part C\n",
    "\n",
    "r_f = np.array([1,1,2])\n",
    "# Find the inverse of F using np.linalg.inv\n",
    "F_inverse = np.linalg.inv(F)\n",
    "\n",
    "# Calculate x: A_inverse * r_f\n",
    "x = F_inverse.dot(r_f)\n",
    "\n",
    "# Part D\n",
    "\n",
    "r_g = np.array([1,1,2])\n",
    "# Find the inverse of G using np.linalg.inv\n",
    "G_inverse = np.linalg.inv(G)\n",
    "\n",
    "# Calculate x: A_inverse * r_f\n",
    "x = G_inverse.dot(r_g)\n",
    "\n",
    "# Part E\n",
    "# Calculate ranks using np.linalg.matrix_rank\n",
    "rank_F = np.linalg.matrix_rank(F)\n",
    "rank_G = np.linalg.matrix_rank(G)\n",
    "\n",
    "# Part F\n",
    "\n",
    "# Given a set of vectors, you can determine if they are linearly independent \n",
    "# by writing the vectors as the columns of the matrix A, and solving Ax = 0. \n",
    "# If there are any non-zero solutions, then the vectors are linearly dependent. \n",
    "# If the only solution is x = 0, then they are linearly independent.\n",
    "\n",
    "# Part G\n",
    "from scipy.linalg import null_space\n",
    "# Compute the null space for matrices F and G\n",
    "null_space_F = null_space(F)\n",
    "null_space_G = null_space(G)\n",
    "print(null_space_F.shape)\n",
    "print(null_space_G.shape)\n",
    "\n",
    "# https://math.stackexchange.com/questions/21131/physical-meaning-of-the-null-space-of-a-matrix\n",
    "\n",
    "# Part H\n",
    "\n",
    "# H.0\n",
    "# The matrix A represents pixel values. The null space are all the pixel values \n",
    "# that the brain would not be able to disginuish or would not ellicit a neural response.\n",
    "\n",
    "# H.1\n",
    "\n",
    "#  we will always be able to completely recover the image when looking at population f and g\n",
    "\n",
    "# If the null-space of the matrix contains only the zero vector, the dimension of its null space is zero. \n",
    "# Hence by the Rankâ€“nullity theorem , the matrix is full rank.\n",
    "\n",
    "# A matrix is full row rank when each of the rows of the matrix are linearly independent \n",
    "# and full column rank when each of the columns of the matrix are linearly independent. \n",
    "# For a square matrix these two concepts are equivalent and we say the matrix is full rank\n",
    "#  if all rows and columns are linearly independent.\n",
    "\n",
    "# If the columns of the matrix G are linearly dependent, it implies that there are redundant \n",
    "# or correlated features or neurons in the network.\n",
    "\n",
    "# When the columns (neurons) of the weight matrix are linearly dependent, it \n",
    "# means that some neurons can be expressed as linear combinations of other neurons in the population. \n",
    "# In other words, there is a redundancy in the representation of information across these neurons. \n",
    "# The information they carry is not fully independent, and some neurons can be predicted or approximated\n",
    "#  using a combination of others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('chatmapenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "266cf4dcda64a063d6a23152384dd9905946d04364795e4134cb273623699d16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
